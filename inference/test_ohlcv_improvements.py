"""
Test improved OHLCV extraction from cleaned_all.parquet data
"""

import pandas as pd
import numpy as np
import sys
from pathlib import Path

# Add the current directory to path
sys.path.insert(0, str(Path(__file__).resolve().parent))

def test_improved_ohlcv_extraction():
    """Test the improved OHLCV extraction method."""
    
    print("üß™ TESTING IMPROVED OHLCV EXTRACTION")
    print("="*60)
    
    # Load sample data
    df = pd.read_parquet('../cleaned_all.parquet')
    
    # Test with a few sample stocks
    sample_stocks = df['id'].unique()[:5]
    
    for i, stock_id in enumerate(sample_stocks):
        print(f"\nüìä Stock {i+1}: {stock_id}")
        print("-" * 40)
        
        # Get stock data
        stock_data = df[df['id'] == stock_id].sort_values('date').head(20)
        print(f"   Data points: {len(stock_data)}")
        print(f"   Date range: {stock_data['date'].min()} to {stock_data['date'].max()}")
        
        if len(stock_data) < 5:
            print("   ‚ö†Ô∏è  Insufficient data, skipping...")
            continue
        
        # Extract key columns
        log_prices = stock_data['prc'].values
        returns = stock_data['stock_ret'].values
        dates = stock_data['date'].values
        
        print(f"   Price range (prc): {log_prices.min():.4f} to {log_prices.max():.4f}")
        print(f"   Return range: {returns.min():.4f} to {returns.max():.4f}")
        
        # Generate OHLCV using improved method
        ohlcv_data = create_realistic_ohlcv(stock_data)
        
        # Show sample OHLCV data
        print(f"\n   üìà Sample OHLCV Data:")
        print(f"   {'Date':<12} {'Open':<8} {'High':<8} {'Low':<8} {'Close':<8} {'Volume':<10} {'Return':<8}")
        print("   " + "-" * 70)
        
        for j in range(min(5, len(ohlcv_data))):
            date_str = str(dates[j])[:10]
            open_p, high_p, low_p, close_p, volume = ohlcv_data[j]
            ret = returns[j]
            
            print(f"   {date_str:<12} {open_p:<8.2f} {high_p:<8.2f} {low_p:<8.2f} {close_p:<8.2f} {volume:<10,} {ret:<8.4f}")
        
        # Validate OHLC relationships
        violations = validate_ohlc_relationships(ohlcv_data)
        if violations == 0:
            print(f"   ‚úÖ All OHLC relationships valid")
        else:
            print(f"   ‚ö†Ô∏è  {violations} OHLC relationship violations")
        
        # Calculate basic statistics
        closes = ohlcv_data[:, 3]  # Close prices
        daily_returns = np.diff(closes) / closes[:-1]
        
        print(f"   üìä Generated price statistics:")
        print(f"      Price range: ${closes.min():.2f} - ${closes.max():.2f}")
        print(f"      Mean daily return: {np.mean(daily_returns):.4f}")
        print(f"      Return volatility: {np.std(daily_returns):.4f}")

def create_realistic_ohlcv(df_stock):
    """Create realistic OHLCV data using the improved method."""
    
    # Get the data
    log_prices = df_stock['prc'].values
    returns = df_stock['stock_ret'].values
    
    # Convert log prices to actual price levels
    base_price = 50.0
    close_prices = base_price * np.exp(log_prices * 0.3)  # Scale factor
    
    num_days = len(close_prices)
    open_prices = np.zeros_like(close_prices)
    high_prices = np.zeros_like(close_prices)
    low_prices = np.zeros_like(close_prices)
    
    for i in range(num_days):
        current_close = close_prices[i]
        current_return = returns[i] if not np.isnan(returns[i]) else 0.0
        
        # Generate Open
        if i == 0:
            open_prices[i] = current_close * (1 + np.random.normal(0, 0.002))
        else:
            overnight_gap = current_return * 0.2
            open_prices[i] = close_prices[i-1] * (1 + overnight_gap)
        
        # Generate High and Low
        intraday_vol = abs(current_return) * 0.4
        
        if current_return >= 0:
            high_prices[i] = max(open_prices[i], current_close) * (1 + intraday_vol)
            low_prices[i] = min(open_prices[i], current_close) * (1 - intraday_vol * 0.3)
        else:
            high_prices[i] = max(open_prices[i], current_close) * (1 + intraday_vol * 0.3)
            low_prices[i] = min(open_prices[i], current_close) * (1 - intraday_vol)
        
        # Ensure OHLC constraints
        low_prices[i] = min(low_prices[i], open_prices[i], current_close)
        high_prices[i] = max(high_prices[i], open_prices[i], current_close)
    
    # Generate Volume
    if 'turnover_126d' in df_stock.columns:
        turnover_norm = df_stock['turnover_126d'].values
        base_volume = 300000
        volumes = base_volume * np.exp(turnover_norm * 0.3)
        volumes = np.clip(volumes, 10000, 5000000)
        volume_multiplier = 1 + np.abs(returns) * 0.15
        volumes = (volumes * volume_multiplier).astype(int)
    else:
        base_volume = 300000
        volume_multiplier = 1 + np.abs(returns) * 0.2
        volumes = (base_volume * volume_multiplier).astype(int)
    
    return np.column_stack([open_prices, high_prices, low_prices, close_prices, volumes])

def validate_ohlc_relationships(ohlcv_data):
    """Validate that OHLC relationships are correct."""
    violations = 0
    
    for i, (open_p, high_p, low_p, close_p, volume) in enumerate(ohlcv_data):
        # Check: Low <= Open, Close <= High
        if not (low_p <= open_p <= high_p):
            violations += 1
            print(f"      Violation at day {i}: Low({low_p:.2f}) <= Open({open_p:.2f}) <= High({high_p:.2f})")
        
        if not (low_p <= close_p <= high_p):
            violations += 1
            print(f"      Violation at day {i}: Low({low_p:.2f}) <= Close({close_p:.2f}) <= High({high_p:.2f})")
    
    return violations

def analyze_ohlcv_quality():
    """Analyze the quality of generated OHLCV data."""
    
    print(f"\nüîç OHLCV DATA QUALITY ANALYSIS")
    print("="*50)
    
    df = pd.read_parquet('../cleaned_all.parquet')
    
    # Sample analysis with multiple stocks
    sample_stocks = df['id'].unique()[:10]
    
    all_close_prices = []
    all_returns = []
    all_volumes = []
    
    for stock_id in sample_stocks:
        stock_data = df[df['id'] == stock_id].sort_values('date').head(50)
        
        if len(stock_data) < 10:
            continue
        
        ohlcv_data = create_realistic_ohlcv(stock_data)
        
        # Extract closes and calculate returns
        closes = ohlcv_data[:, 3]
        volumes = ohlcv_data[:, 4]
        returns = np.diff(closes) / closes[:-1]
        
        all_close_prices.extend(closes)
        all_returns.extend(returns)
        all_volumes.extend(volumes)
    
    # Overall statistics
    print(f"üìä AGGREGATE STATISTICS:")
    print(f"   Sample size: {len(all_close_prices):,} price points from {len(sample_stocks)} stocks")
    print(f"\n   üí∞ Price Statistics:")
    print(f"      Range: ${np.min(all_close_prices):.2f} - ${np.max(all_close_prices):.2f}")
    print(f"      Mean: ${np.mean(all_close_prices):.2f}")
    print(f"      Median: ${np.median(all_close_prices):.2f}")
    
    print(f"\n   üìà Return Statistics:")
    print(f"      Mean daily return: {np.mean(all_returns):.4f} ({np.mean(all_returns)*252:.2f}% annualized)")
    print(f"      Daily volatility: {np.std(all_returns):.4f} ({np.std(all_returns)*np.sqrt(252):.2f}% annualized)")
    print(f"      Range: {np.min(all_returns):.4f} to {np.max(all_returns):.4f}")
    
    print(f"\n   üìä Volume Statistics:")
    print(f"      Range: {np.min(all_volumes):,} - {np.max(all_volumes):,} shares")
    print(f"      Mean: {np.mean(all_volumes):,.0f} shares")
    print(f"      Median: {np.median(all_volumes):,.0f} shares")
    
    # Quality assessment
    print(f"\n‚úÖ QUALITY ASSESSMENT:")
    reasonable_prices = np.sum((np.array(all_close_prices) >= 5) & (np.array(all_close_prices) <= 500))
    reasonable_volumes = np.sum((np.array(all_volumes) >= 1000) & (np.array(all_volumes) <= 50000000))
    reasonable_returns = np.sum(np.abs(all_returns) <= 0.5)  # Daily returns within ¬±50%
    
    print(f"   Reasonable prices (5-500): {reasonable_prices}/{len(all_close_prices)} ({reasonable_prices/len(all_close_prices)*100:.1f}%)")
    print(f"   Reasonable volumes (1K-50M): {reasonable_volumes}/{len(all_volumes)} ({reasonable_volumes/len(all_volumes)*100:.1f}%)")
    print(f"   Reasonable returns (¬±50%): {reasonable_returns}/{len(all_returns)} ({reasonable_returns/len(all_returns)*100:.1f}%)")
    
    if (reasonable_prices/len(all_close_prices) > 0.9 and 
        reasonable_volumes/len(all_volumes) > 0.9 and 
        reasonable_returns/len(all_returns) > 0.9):
        print(f"\nüéâ EXCELLENT: Generated OHLCV data quality is very good!")
    else:
        print(f"\n‚ö†Ô∏è  WARNING: Some data quality issues detected")

def compare_with_synthetic_vs_realistic():
    """Compare synthetic vs realistic OHLCV generation methods."""
    
    print(f"\n‚öîÔ∏è  SYNTHETIC vs REALISTIC OHLCV COMPARISON")
    print("="*60)
    
    df = pd.read_parquet('../cleaned_all.parquet')
    sample_stock = df[df['id'] == df['id'].iloc[0]].sort_values('date').head(10)
    
    print(f"üìä Comparing methods for stock: {sample_stock['id'].iloc[0]}")
    
    # Method 1: Simple synthetic (old approach)
    print(f"\nü§ñ METHOD 1: Simple Synthetic")
    close_prices = np.full(len(sample_stock), 50.0)
    synthetic_ohlcv = np.column_stack([
        close_prices * 1.001,  # Open
        close_prices * 1.01,   # High  
        close_prices * 0.99,   # Low
        close_prices,          # Close
        np.full(len(sample_stock), 1000000)  # Volume
    ])
    
    print(f"   Price range: ${synthetic_ohlcv[:, 3].min():.2f} - ${synthetic_ohlcv[:, 3].max():.2f}")
    print(f"   Daily volatility: {np.std(np.diff(synthetic_ohlcv[:, 3]) / synthetic_ohlcv[:-1, 3]):.6f}")
    
    # Method 2: Realistic approach (new approach)
    print(f"\nüéØ METHOD 2: Realistic Data-Driven")
    realistic_ohlcv = create_realistic_ohlcv(sample_stock)
    realistic_returns = np.diff(realistic_ohlcv[:, 3]) / realistic_ohlcv[:-1, 3]
    
    print(f"   Price range: ${realistic_ohlcv[:, 3].min():.2f} - ${realistic_ohlcv[:, 3].max():.2f}")
    print(f"   Daily volatility: {np.std(realistic_returns):.6f}")
    print(f"   Volume range: {realistic_ohlcv[:, 4].min():,} - {realistic_ohlcv[:, 4].max():,}")
    
    # Original data comparison
    original_returns = sample_stock['stock_ret'].values
    print(f"\nüìä ORIGINAL DATA COMPARISON:")
    print(f"   Original return volatility: {np.std(original_returns):.6f}")
    print(f"   Realistic method captures: {np.std(realistic_returns)/np.std(original_returns)*100:.1f}% of original volatility")
    
    print(f"\nüèÜ WINNER: Realistic Data-Driven Method")
    print("   ‚úÖ Uses actual market data from your dataset")
    print("   ‚úÖ Preserves volatility patterns")
    print("   ‚úÖ No external data dependencies")
    print("   ‚úÖ Solves ticker matching problem")

if __name__ == "__main__":
    test_improved_ohlcv_extraction()
    analyze_ohlcv_quality()
    compare_with_synthetic_vs_realistic()